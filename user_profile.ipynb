{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers as ppb\n",
    "from transformers import AdamW\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "import os.path as path\n",
    "\n",
    "import sklearn\n",
    "import scipy\n",
    "\n",
    "# print messages\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device type: {device.type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_TRAIN = \"./data/splitted/user_profile_processed_train.csv\"\n",
    "DATASET_CV = \"./data/splitted/user_profile_processed_cv.csv\"\n",
    "DATASET_TEST = \"./data/splitted/user_profile_processed_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATASET_TRAIN, header = 0)\n",
    "cv_df = pd.read_csv(DATASET_CV, header = 0)\n",
    "test_df = pd.read_csv(DATASET_TEST, header = 0)\n",
    "\n",
    "print(f\"Columns: {train_df.columns}\")\n",
    "print(f\"train set size: {len(train_df)}\")\n",
    "print(f\"cross validation set size: {len(cv_df)}\")\n",
    "print(f\"test set size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # load pretrained tokenizer\n",
    "\n",
    "# For DistilBERT:\n",
    "tokenizer = ppb.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "train_des_tokenized = train_df['description'].apply(lambda x: tokenizer.encode(x, add_special_tokens = True))\n",
    "cv_des_tokenized = cv_df['description'].apply(lambda x: tokenizer.encode(x, add_special_tokens = True))\n",
    "test_des_tokenized = test_df['description'].apply(lambda x: tokenizer.encode(x, add_special_tokens = True))\n",
    "\n",
    "print(f\"train tokenized shape: {train_des_tokenized.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_length = 0\n",
    "\n",
    "for i in train_des_tokenized.values:\n",
    "    total_length += len(i)\n",
    "for i in cv_des_tokenized.values:\n",
    "    total_length += len(i)\n",
    "for i in test_des_tokenized.values:\n",
    "    total_length += len(i)\n",
    "    \n",
    "average_length = int(total_length / (train_des_tokenized.shape[0] + cv_des_tokenized.shape[0] + test_des_tokenized.shape[0]))\n",
    "print(average_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how much proportion of self description is empty\n",
    "\n",
    "empty_count = 0\n",
    "\n",
    "for i in train_df['description'].values:\n",
    "    if i == ' ':\n",
    "        empty_count += 1\n",
    "for i in cv_df['description'].values:\n",
    "    if i == ' ':\n",
    "        empty_count += 1\n",
    "for i in test_df['description'].values:\n",
    "    if i == ' ':\n",
    "        empty_count += 1\n",
    "        \n",
    "print(empty_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate description using average length\n",
    "for i in range(len(train_des_tokenized)):\n",
    "    train_des_tokenized[i] = train_des_tokenized[i][:average_length]\n",
    "for i in range(len(cv_des_tokenized)):\n",
    "    cv_des_tokenized[i] = cv_des_tokenized[i][:average_length]\n",
    "for i in range(len(test_des_tokenized)):\n",
    "    test_des_tokenized[i] = test_des_tokenized[i][:average_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "train_des_padded = np.array([i + [0] * (average_length - len(i)) for i in train_des_tokenized.values])\n",
    "cv_des_padded = np.array([i + [0] * (average_length - len(i)) for i in cv_des_tokenized.values])\n",
    "test_des_padded = np.array([i + [0] * (average_length - len(i)) for i in test_des_tokenized.values])\n",
    "\n",
    "print(f\"train_padded: {train_des_padded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masking\n",
    "train_attention_mask = np.where(train_des_padded != 0, 1, 0)\n",
    "cv_attention_mask = np.where(cv_des_padded != 0, 1, 0)\n",
    "test_attention_mask = np.where(test_des_padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put into GPU\n",
    "train_text_tensors = torch.tensor(train_des_padded, dtype=torch.long).to(device)\n",
    "cv_text_tensors = torch.tensor(cv_des_padded, dtype=torch.long).to(device)\n",
    "test_text_tensors = torch.tensor(test_des_padded, dtype=torch.long).to(device)\n",
    "\n",
    "train_text_mask = torch.tensor(train_attention_mask, dtype=torch.long).to(device)\n",
    "cv_text_mask = torch.tensor(cv_attention_mask, dtype=torch.long).to(device)\n",
    "test_text_mask = torch.tensor(test_attention_mask, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_column_names = ['followers_count', 'friends_count', 'listed_count', 'favorites_count', 'statuses_count']\n",
    "boolean_column_names = ['protected', 'geo_enabled', 'verified']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Boolean to 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {True: 1, False: 0}\n",
    "\n",
    "for c in boolean_column_names:\n",
    "    train_df[c] = train_df[c].map(d)\n",
    "    cv_df[c] = cv_df[c].map(d)\n",
    "    test_df[c] = test_df[c].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_numeric_tensors = torch.tensor(train_df[boolean_column_names+numeric_column_names].values, dtype=torch.float).to(device)\n",
    "cv_numeric_tensors = torch.tensor(cv_df[boolean_column_names+numeric_column_names].values, dtype=torch.float).to(device)\n",
    "test_numeric_tensors = torch.tensor(test_df[boolean_column_names+numeric_column_names].values, dtype=torch.float).to(device)\n",
    "\n",
    "print(train_numeric_tensors.shape)\n",
    "print(cv_numeric_tensors.shape)\n",
    "print(test_numeric_tensors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = torch.tensor(train_df['cascade_size'].values, dtype=torch.float).unsqueeze(1).to(device)\n",
    "cv_labels = torch.tensor(cv_df['cascade_size'].values, dtype=torch.float).unsqueeze(1).to(device)\n",
    "test_labels = torch.tensor(test_df['cascade_size'].values, dtype=torch.float).unsqueeze(1).to(device)\n",
    "\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downstream model\n",
    "class PopularityModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, text_in_dimension = 768, text_to_dimension = 32, numeric_in_dimension = 8):\n",
    "        super(PopularityModel, self).__init__()\n",
    "        \n",
    "        self.text_linear = nn.Linear(text_in_dimension, text_to_dimension)\n",
    "        \n",
    "        self.mlp_input_dim = text_to_dimension + numeric_in_dimension\n",
    "        \n",
    "        self.linear1 = nn.Linear(self.mlp_input_dim, int(self.mlp_input_dim/2))\n",
    "        self.linear2 = nn.Linear(int(self.mlp_input_dim/2), int(self.mlp_input_dim/4))\n",
    "        self.linear3 = nn.Linear(int(self.mlp_input_dim/4), 1)\n",
    "        \n",
    "    def forward(self, embedded, numeric):\n",
    "        \n",
    "        text_downsampled = F.relu(self.text_linear(embedded))\n",
    "        \n",
    "        # concatenate text with numeric features\n",
    "        y = torch.cat((text_downsampled, numeric), 1)\n",
    "        \n",
    "        y = F.relu(self.linear1(y))\n",
    "        y = F.relu(self.linear2(y))\n",
    "        y = F.relu(self.linear3(y))\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for Ranking\n",
    "\n",
    "* Accuracy@K (Hit Rate)\n",
    "* NDCG@K\n",
    "\n",
    "`note`: Here we define K = 1%, 5%, 10%, 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_at_k(predicted, labels, k = 10):\n",
    "    \n",
    "    # check whether both sizes are identical\n",
    "    assert predicted.size(0) == labels.size(0)\n",
    "    \n",
    "    # sort the values in descending order and gets the indexs\n",
    "    sorted_predicted_index = torch.argsort(predicted, descending = True)\n",
    "    sorted_label_index = torch.argsort(labels, descending = True)\n",
    "    \n",
    "    k_number = max(int(predicted.size(0) * k / 100), 1)\n",
    "    \n",
    "    topk_predicted_index = sorted_predicted_index[:k_number]\n",
    "    topk_label_index = sorted_label_index[:k_number]\n",
    "    \n",
    "    hit_count = 0\n",
    "    for p in topk_predicted_index:\n",
    "        if p in topk_label_index:\n",
    "            hit_count += 1\n",
    "            \n",
    "    accuracy = hit_count/k_number\n",
    "            \n",
    "    return (accuracy, hit_count, k_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Automatic training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_BERT = 1e-5\n",
    "LR_REGRESSION = 1e-3\n",
    "EPOCH = 10000\n",
    "BATCH_SIZE = 4800\n",
    "EARLY_STOP_PATIENCE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lr_regression=LR_REGRESSION, lr_bert=LR_BERT, max_epoch=EPOCH, batch_size=BATCH_SIZE, early_stop_patience=EARLY_STOP_PATIENCE, verbose=True, manual_seed=None):\n",
    "    \n",
    "    if manual_seed:\n",
    "        seed = manual_seed\n",
    "    else:\n",
    "        seed = torch.random.seed()\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # downstream model\n",
    "    popularity_model = PopularityModel(text_in_dimension = 768, text_to_dimension = 768, numeric_in_dimension = 8).to(device)\n",
    "    popularity_model.train()\n",
    "\n",
    "    # BERT\n",
    "    bert_model = ppb.DistilBertModel.from_pretrained('distilbert-base-uncased').to(device)\n",
    "\n",
    "    # fine-tune only last layer of BERT\n",
    "    for param in bert_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for p in bert_model.transformer.layer[len(bert_model.transformer.layer) - 1].parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "    # optimizer instances\n",
    "    optimizer_bert = AdamW(bert_model.parameters(), lr = lr_bert)\n",
    "    optimizer_regression = torch.optim.Adam(popularity_model.parameters(), lr = lr_regression)\n",
    "    \n",
    "    train_losses = []\n",
    "\n",
    "    # cross validation for early stopping\n",
    "    current_val_error = float('inf')\n",
    "    val_error_inc_count = 0\n",
    "    cv_losses = []\n",
    "    \n",
    "    for epoch in range(max_epoch):\n",
    "    \n",
    "        if verbose:\n",
    "            print(f\"{epoch}\", end=\".\")\n",
    "\n",
    "        batch_losses = []\n",
    "\n",
    "        # batch training\n",
    "        for i in range(0, train_labels.size(0), batch_size):\n",
    "            \n",
    "            if verbose and i%(4*batch_size) == 0:\n",
    "                print(\".\", end=\"\")\n",
    "\n",
    "            optimizer_regression.zero_grad()\n",
    "            optimizer_bert.zero_grad()\n",
    "\n",
    "            END = (i + batch_size) if (i + batch_size) < train_labels.size(0) else train_labels.size(0)\n",
    "            \n",
    "            batch_text_features = train_text_tensors[i:END]\n",
    "            batch_text_mask = train_text_mask[i:END]\n",
    "            batch_numeric_features = train_numeric_tensors[i:END]\n",
    "            batch_labels = train_labels[i:END]\n",
    "\n",
    "            # forward: BERT embedding\n",
    "            last_hidden_states = bert_model(batch_text_features, attention_mask=batch_text_mask)\n",
    "\n",
    "            # The embedded CLS token can be thought of as an embedding for the entire sentence!!\n",
    "            embedded = last_hidden_states[0][:, 0, :]\n",
    "\n",
    "            # forward: Linear Regression\n",
    "            predicted = popularity_model(embedded, batch_numeric_features)\n",
    "\n",
    "            # compute loss (weighted mean squared error)\n",
    "            loss = F.mse_loss(predicted, batch_labels, reduction='mean')\n",
    "            # loss = WeightedMSELoss(predicted, batch_labels) # bigger penalty on bigger cascade\n",
    "\n",
    "            # backward propagation\n",
    "            loss.backward()\n",
    "            optimizer_regression.step()\n",
    "            optimizer_bert.step()\n",
    "\n",
    "            batch_losses.append(loss)\n",
    "\n",
    "        train_losses.append(torch.tensor(batch_losses).mean().item())\n",
    "\n",
    "        # cross validation & early stopping\n",
    "        with torch.no_grad():\n",
    "\n",
    "            batch_losses = []\n",
    "            for i in range(0, cv_labels.size(0), batch_size):\n",
    "\n",
    "                END = (i + batch_size) if (i + batch_size) < cv_labels.size(0) else cv_labels.size(0)\n",
    "\n",
    "                batch_text_features = cv_text_tensors[i:END]\n",
    "                batch_text_mask = cv_text_mask[i:END]\n",
    "                batch_numeric_features = cv_numeric_tensors[i:END]\n",
    "                batch_labels = cv_labels[i:END]\n",
    "\n",
    "                # forward: BERT embedding\n",
    "                last_hidden_states = bert_model(batch_text_features, attention_mask=batch_text_mask)\n",
    "\n",
    "                # The embedded CLS token can be thought of as an embedding for the entire sentence!!\n",
    "                embedded = last_hidden_states[0][:, 0, :]\n",
    "\n",
    "                # forward: Linear Regression\n",
    "                predicted = popularity_model(embedded, batch_numeric_features)\n",
    "\n",
    "                # compute loss (weighted mean squared error)\n",
    "                loss = F.mse_loss(predicted, batch_labels, reduction='mean')\n",
    "                # loss = WeightedMSELoss(predicted, batch_labels) # bigger penalty on bigger cascade\n",
    "\n",
    "                batch_losses.append(loss)\n",
    "\n",
    "            cv_error = torch.tensor(batch_losses).mean().item()\n",
    "            cv_losses.append(cv_error)\n",
    "\n",
    "            if cv_error >= current_val_error:\n",
    "                val_error_inc_count += 1\n",
    "                current_val_error = cv_error\n",
    "                if val_error_inc_count >= early_stop_patience:\n",
    "                    if verbose:\n",
    "                        print(f\"early stopping triggered! stopped at epoch {epoch}\")\n",
    "                    break\n",
    "            else:\n",
    "                val_error_inc_count = 0\n",
    "                current_val_error = cv_error\n",
    "                \n",
    "    with torch.no_grad():\n",
    "\n",
    "        model_test_predicted = torch.zeros((test_labels.size(0),), dtype=torch.float).to(device)\n",
    "        for i in range(0, test_labels.size(0), batch_size):\n",
    "\n",
    "            END = (i + batch_size) if (i + batch_size) < test_labels.size(0) else test_labels.size(0)\n",
    "\n",
    "            batch_text_features = test_text_tensors[i:END]\n",
    "            batch_text_mask = test_text_mask[i:END]\n",
    "            batch_numeric_features = test_numeric_tensors[i:END]\n",
    "            batch_labels = test_labels[i:END].unsqueeze(1)\n",
    "\n",
    "            # forward: BERT embedding\n",
    "            last_hidden_states = bert_model(batch_text_features, attention_mask=batch_text_mask)\n",
    "\n",
    "            # The embedded CLS token can be thought of as an embedding for the entire sentence!!\n",
    "            embedded = last_hidden_states[0][:, 0, :]\n",
    "\n",
    "            # forward: Linear Regression\n",
    "            model_test_predicted[i:END] = popularity_model(embedded, batch_numeric_features).squeeze(1)\n",
    "\n",
    "        testset_size = test_labels.size(0)\n",
    "\n",
    "        model_mae_scores = F.l1_loss(model_test_predicted, test_labels)\n",
    "        model_mse_scores = F.mse_loss(model_test_predicted, test_labels)\n",
    "\n",
    "        hit_rate_top1p = accuracy_at_k(model_test_predicted, test_labels.squeeze(1), 1)\n",
    "        hit_rate_top5p = accuracy_at_k(model_test_predicted, test_labels.squeeze(1), 5)\n",
    "        hit_rate_top10p = accuracy_at_k(model_test_predicted, test_labels.squeeze(1), 10)\n",
    "        hit_rate_top15p = accuracy_at_k(model_test_predicted, test_labels.squeeze(1), 15)\n",
    "\n",
    "        ndcg_score_1p = sklearn.metrics.ndcg_score(test_labels.reshape((1, -1)).cpu(), model_test_predicted.unsqueeze(0).cpu(), k=int(testset_size * 1 / 100))\n",
    "        ndcg_score_5p = sklearn.metrics.ndcg_score(test_labels.reshape((1, -1)).cpu(), model_test_predicted.unsqueeze(0).cpu(), k=int(testset_size * 5 / 100))\n",
    "        ndcg_score_10p = sklearn.metrics.ndcg_score(test_labels.reshape((1, -1)).cpu(), model_test_predicted.unsqueeze(0).cpu(), k=int(testset_size * 10 / 100))\n",
    "        ndcg_score_15p = sklearn.metrics.ndcg_score(test_labels.reshape((1, -1)).cpu(), model_test_predicted.unsqueeze(0).cpu(), k=int(testset_size * 15 / 100))\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"seed: {seed}\")\n",
    "            print(f\"MAE: {model_mae_scores.item()}\")\n",
    "            print(f\"MSE: {model_mse_scores.item()}\")\n",
    "            print(f\"Hit Rate@1%: {hit_rate_top1p}\")\n",
    "            print(f\"Hit Rate@5%: {hit_rate_top5p}\")\n",
    "            print(f\"Hit Rate@10%: {hit_rate_top10p}\")\n",
    "            print(f\"Hit Rate@15%: {hit_rate_top15p}\")\n",
    "            print(f\"NDCG@1%: {ndcg_score_1p}\")\n",
    "            print(f\"NDCG@5%: {ndcg_score_5p}\")\n",
    "            print(f\"NDCG@10%: {ndcg_score_10p}\")\n",
    "            print(f\"NDCG@15%: {ndcg_score_15p}\")\n",
    "            \n",
    "            # plot loss curve\n",
    "            plt.plot(train_losses, label = 'training')\n",
    "            plt.plot(cv_losses, label = 'validation')\n",
    "            plt.xlabel('epoch'), plt.ylabel('MSE')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "        # clear useless CUDA memory\n",
    "        torch.cuda.empty_cache()\n",
    "        popularity_model = None\n",
    "        bert_model = None\n",
    "        optimizer_regression = None\n",
    "        optimizer_bert = None\n",
    "        batch_text_features = None\n",
    "        batch_text_mask = None\n",
    "        batch_numeric_features = None\n",
    "        batch_labels = None\n",
    "        last_hidden_states = None\n",
    "        embedded = None\n",
    "        predicted = None\n",
    "        loss = None\n",
    "        \n",
    "        return {\n",
    "            'seed': seed,\n",
    "            'mae': model_mae_scores.item(),\n",
    "            'mse': model_mse_scores.item(),\n",
    "            'hr1p': hit_rate_top1p[0],\n",
    "            'hr5p': hit_rate_top5p[0],\n",
    "            'hr10p': hit_rate_top10p[0],\n",
    "            'hr15p': hit_rate_top15p[0],\n",
    "            'ndcg1p': ndcg_score_1p,\n",
    "            'ndcg5p': ndcg_score_5p,\n",
    "            'ndcg10p': ndcg_score_10p,\n",
    "            'ndcg15p': ndcg_score_15p,\n",
    "            'train_losses': train_losses,\n",
    "            'cv_losses': cv_losses\n",
    "        };"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(2):\n",
    "    print(f\"No.{i+1} model:\")\n",
    "\n",
    "    res = train(lr_regression=LR_REGRESSION, lr_bert=LR_BERT, max_epoch=EPOCH, batch_size = BATCH_SIZE, early_stop_patience=EARLY_STOP_PATIENCE, verbose=True)\n",
    "    res['number'] = i\n",
    "    res['score'] = res['hr1p'] + res['hr5p'] + res['hr10p'] + res['hr15p'] + res['ndcg1p'] + res['ndcg5p'] + res['ndcg10p'] + res['ndcg15p']\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results = sorted(results, key = lambda k: k['score'], reverse=True)\n",
    "sorted_results[:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
